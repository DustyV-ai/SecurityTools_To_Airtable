import requests
from datetime import datetime, timedelta
import pandas as pd
import time
from base64 import b64encode
from collections import defaultdict
import logging
from urllib.parse import urlparse, parse_qs

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Airtable configuration (Replace with your actual values)
AIRTABLE_API_KEY = ""
AIRTABLE_BASE_ID = ""
AIRTABLE_TABLE_NAME = ""

# API Rate Limiting - Adjust as needed
REQUESTS_PER_MINUTE = 60  # Example: Limit to 60 requests per minute
SECONDS_PER_REQUEST = 60 / REQUESTS_PER_MINUTE

# DarkWeb ID API endpoint
BASE_URL = "https://secure.darkwebid.com"

def get_auth_header(username, password):
    """Create Basic Auth header from credentials"""
    credentials = f"{username}:{password}"
    encoded = b64encode(credentials.encode()).decode()
    return {"Authorization": f"Basic {encoded}"}

def get_organizations(base_url, auth_header, page=0, limit=200):
    """Fetch all organizations from the API with pagination"""
    all_organizations = []
    url = f"{base_url}/services/organization.json"

    while True:
        params = {
            'page': page,
            'limit': limit
        }
        try:
            response = requests.get(url, headers=auth_header, params=params)
            response.raise_for_status()
            data = response.json()
            all_organizations.extend(data['list'])

            # Check for the next page using the 'next' URL
            next_page_url = data.get('next')
            if not next_page_url:
                break

            # Parse the next page URL to get the next page number
            parsed_url = urlparse(next_page_url)
            query_params = parse_qs(parsed_url.query)
            page = int(query_params.get('page', [page])[0])

            # Rate limiting
            time.sleep(SECONDS_PER_REQUEST)

        except requests.exceptions.RequestException as e:
            logging.error(f"Error fetching organizations: {str(e)}")
            print(f"Error fetching organizations: {str(e)}")
            return []  # Return empty list on error

    return all_organizations

def get_compromises(base_url, auth_header, start_date, end_date, org_uuids=None, page=0, limit=200):
    """Fetch compromises from the API with pagination and filtering"""
    url = f"{base_url}/services/compromise.json"
    params = {
        'page': page,
        'limit': limit,
        'beginDate': start_date.strftime('%Y-%m-%d %H:%M:%S'),
        'endDate': end_date.strftime('%Y-%m-%d %H:%M:%S')
    }
    if org_uuids:
        params['organization[]'] = org_uuids

    response = requests.get(url, headers=auth_header, params=params)
    response.raise_for_status()
    data = response.json()
    compromises = data.get('list', [])

    # Recursively fetch next page if available
    next_page_url = data.get('next')
    if next_page_url:
        # Parse the URL
        parsed_url = urlparse(next_page_url)
        # Parse the query string
        query_params = parse_qs(parsed_url.query)

        # Extract the 'page' parameter
        next_page = int(query_params.get('page', [0])[0])

        # Simple rate limiting
        time.sleep(SECONDS_PER_REQUEST)

        compromises.extend(get_compromises(base_url, auth_header, start_date, end_date, org_uuids, page=next_page, limit=limit))

    return compromises

def get_previous_quarter_date_range(current_date: datetime):
    """
    Calculates the start and end dates of the previous quarter.

    Args:
        current_date: The current date.

    Returns:
        A tuple containing the start and end dates of the previous quarter.
    """
    if 1 <= current_date.month <= 3:
        # Current quarter is Q1, so previous quarter is Q4 of previous year
        start_date = datetime(current_date.year - 1, 10, 1)
        end_date = datetime(current_date.year - 1, 12, 31)
    elif 4 <= current_date.month <= 6:
        # Current quarter is Q2
        start_date = datetime(current_date.year, 1, 1)
        end_date = datetime(current_date.year, 3, 31)
    elif 7 <= current_date.month <= 9:
        # Current quarter is Q3
        start_date = datetime(current_date.year, 4, 1)
        end_date = datetime(current_date.year, 6, 30)
    else:
        # Current quarter is Q4
        start_date = datetime(current_date.year, 7, 1)
        end_date = datetime(current_date.year, 9, 30)

    return start_date, end_date

def get_quarter(timestamp):
    """Convert timestamp to quarter string"""
    dt = datetime.fromtimestamp(timestamp)
    return f"{dt.year}Q{(dt.month-1)//3 + 1}"

def get_last_day_of_quarter(quarter_label: str) -> str:
    """
    Get the last day of the quarter as a string in YYYY-MM-DD format.

    Args:
        quarter_label: The quarter label (e.g., "2023-Q3").

    Returns:
        The last day of the quarter in YYYY-MM-DD format.
    """
    year = int(quarter_label.split("Q")[0])
    quarter = int(quarter_label.split("Q")[1])

    if quarter == 1:
        last_day = datetime(year, 3, 31)
    elif quarter == 2:
        last_day = datetime(year, 6, 30)
    elif quarter == 3:
        last_day = datetime(year, 9, 30)
    else:  # quarter == 4
        last_day = datetime(year, 12, 31)

    return last_day.strftime("%Y-%m-%d")

def upload_to_airtable(data, quarter_label):
    """Uploads the compromise data to Airtable for the specified quarter."""
    airtable_url = f"https://api.airtable.com/v0/{AIRTABLE_BASE_ID}/{AIRTABLE_TABLE_NAME}"
    headers = {
        "Authorization": f"Bearer {AIRTABLE_API_KEY}",
        "Content-Type": "application/json"
    }

    for company, quarters in data.items():
        stats = quarters.get(quarter_label, {'total': 0})
        last_day = get_last_day_of_quarter(quarter_label)
        fields = {
            "Company Name": company,
            "Compromises": stats['total'],
            "Quarter": last_day
        }

        record_data = {"fields": fields}

        try:
            response = requests.post(airtable_url, headers=headers, json=record_data)
            response.raise_for_status()
            logging.info(f"Successfully uploaded data for {company}, {quarter_label} to Airtable")
            print(f"Successfully uploaded data for {company}, {quarter_label} to Airtable")

        except requests.exceptions.HTTPError as e:
            logging.error(f"HTTP error while uploading data for {company}, {quarter_label}: {e.response.status_code} - {e.response.text}")
            print(f"HTTP error while uploading data for {company}, {quarter_label}: {e.response.status_code} - {e.response.text}")

        except requests.exceptions.RequestException as e:
            logging.error(f"Failed to upload data to Airtable for {company}, {quarter_label}: {str(e)}")
            print(f"Failed to upload data to Airtable for {company}, {quarter_label}: {str(e)}")

        finally:
            time.sleep(SECONDS_PER_REQUEST)
            print(f"Waiting {SECONDS_PER_REQUEST} seconds due to rate limiting...")

def analyze_compromises(base_url, username, password):
    """Main function to analyze compromises by company and quarter"""
    auth_header = get_auth_header(username, password)

    # Get all organizations with pagination
    logging.info("Fetching organizations...")
    print("Fetching organizations...")
    orgs = get_organizations(base_url, auth_header)
    logging.info(f"Fetched {len(orgs)} organizations.")
    print(f"Fetched {len(orgs)} organizations.")

    # Calculate date range for the previous quarter
    current_date = datetime.now()
    start_date, end_date = get_previous_quarter_date_range(current_date)
    print(f"Start Date: {start_date}")  # Debug print
    print(f"End Date: {end_date}")  # Debug print

    # Get the quarter label for the previous quarter
    quarter_label = get_quarter(start_date.timestamp())

    # Initialize data structures for tracking
    quarterly_stats = defaultdict(lambda: defaultdict(lambda: {'total': 0}))

    # Get all organization UUIDs
    org_uuids = [org['uuid'] for org in orgs]

    # Fetch all compromises for all organizations within the date range
    logging.info("Fetching compromises...")
    print("Fetching compromises...")
    all_compromises = get_compromises(base_url, auth_header, start_date, end_date, org_uuids)

    # Initialize quarterly_stats with all fetched orgs for the previous quarter
    for org in orgs:
        quarterly_stats[org['title']][quarter_label] = {'total': 0}

    # Create a mapping of organization UUIDs to names for faster lookup
    org_name_map = {org['uuid']: org['title'] for org in orgs}

    # Process each compromise
    logging.info("Processing compromises...")
    print("Processing compromises...")
    for comp in all_compromises:
        # Only process compromises where the password field has data
        if comp.get('password') is None or not comp.get('password'):
            continue

        org_id = comp['organization']
        occurred_date = datetime.fromtimestamp(comp['occurred'])
        company_name = org_name_map.get(org_id, "Unknown Organization")

        # Check if compromise is within our date range
        if start_date <= occurred_date <= end_date:
            quarter = get_quarter(comp['occurred'])
            if quarter == quarter_label:
                quarterly_stats[company_name][quarter]['total'] += 1

    # Upload results to Airtable
    logging.info("Uploading results to Airtable...")
    print("Uploading results to Airtable...")
    upload_to_airtable(quarterly_stats, quarter_label)

    logging.info("Data successfully uploaded to Airtable!")
    print("Data successfully uploaded to Airtable!")

if __name__ == "__main__":
    USERNAME = ""
    PASSWORD = ""

    analyze_compromises(BASE_URL, USERNAME, PASSWORD)
